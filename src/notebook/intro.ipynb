{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workshop - Introduksjon\n",
    "\n",
    "Velkommen til workshop om **Retrieval-Augmented Generation (RAG)** med Google Cloud Platform!\n",
    "\n",
    "I denne workshopen skal vi bygge et komplett RAG-system som bruker:\n",
    "- ğŸ“„ **Dokumentavgift 2025** som kunnskapsbase\n",
    "- ğŸ—„ï¸ **Cloud SQL (PostgreSQL + pgvector)** som vector database\n",
    "- ğŸ¤– **Vertex AI** for embeddings og language models\n",
    "- ğŸ” **Secret Manager** for sikker hÃ¥ndtering av credentials\n",
    "\n",
    "## Hva er RAG?\n",
    "\n",
    "RAG kombinerer sÃ¸k (retrieval) med generering (generation) for Ã¥ gi LLM-er tilgang til ekstern kunnskap:\n",
    "\n",
    "1. **Retrieval**: Finn relevant informasjon fra en kunnskapsbase\n",
    "2. **Augmentation**: Berik spÃ¸rsmÃ¥let med den hentede informasjonen  \n",
    "3. **Generation**: Bruk en LLM til Ã¥ generere svar basert pÃ¥ konteksten\n",
    "\n",
    "### Hvorfor RAG?\n",
    "\n",
    "- âœ… **Oppdatert informasjon**: Ikke begrenset til treningsdata\n",
    "- âœ… **Faktabaserte svar**: Reduserer hallusinasjoner\n",
    "- âœ… **Kilder**: Kan referere til hvor informasjonen kommer fra\n",
    "- âœ… **Privat data**: Kan bruke bedriftsintern dokumentasjon\n",
    "\n",
    "## Workshop-arkitektur\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Dokumentavgift  â”‚\n",
    "â”‚   PDF (2025)    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ PDF Extraction  â”‚ â† pymupdf4llm\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚    Chunking     â”‚ â† LangChain\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Vertex AI     â”‚ â† text-embedding-004\n",
    "â”‚   Embeddings    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Cloud SQL     â”‚ â† PostgreSQL + pgvector\n",
    "â”‚  (pgvector)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "  Query â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Vector Search   â”‚ â† Similarity search\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Vertex AI     â”‚ â† gemini-2.0-flash-001\n",
    "â”‚   Generation    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚     Answer      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup og konfigurasjon\n",
    "\n",
    "### ğŸ”§ MiljÃ¸-deteksjon\n",
    "\n",
    "Denne notebooken fungerer bÃ¥de lokalt og i Google Colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detekter om vi kjÃ¸rer i Colab\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸŒ KjÃ¸rer i Google Colab\")\n",
    "else:\n",
    "    print(\"ğŸ’» KjÃ¸rer lokalt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â˜ï¸ Google Colab Setup\n",
    "\n",
    "**Hvis du bruker Google Colab, fÃ¸lg disse stegene:**\n",
    "\n",
    "1. **Last opp PDF til Colab**\n",
    "2. **Autentiser med GCP** (via Google Account)\n",
    "3. **Installer pakker** (kjÃ¸res automatisk)\n",
    "\n",
    "**Hvis du kjÃ¸rer lokalt, hopp over disse cellene!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB: Installer pakker\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ Installerer pakker for Colab...\")\n",
    "    !pip install -q pymupdf4llm langchain-text-splitters google-cloud-secret-manager google-genai psycopg2-binary pgvector\n",
    "    print(\"âœ… Pakker installert!\")\n",
    "else:\n",
    "    print(\"â­ï¸  Hopper over - kjÃ¸rer lokalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB: Last opp PDF\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    print(\"ğŸ“¤ Last opp dokumentavgift-2025.pdf:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Flytt til forventet sti\n",
    "    if uploaded:\n",
    "        filename = list(uploaded.keys())[0]\n",
    "        shutil.move(filename, 'dokumentavgift-2025.pdf')\n",
    "        print(f\"âœ… PDF lastet opp: dokumentavgift-2025.pdf\")\n",
    "else:\n",
    "    print(\"â­ï¸  Hopper over - kjÃ¸rer lokalt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB: GCP Autentisering\n",
    "if IN_COLAB:\n",
    "    from google.colab import auth\n",
    "    print(\"ğŸ” Autentiserer med GCP...\")\n",
    "    auth.authenticate_user()\n",
    "    print(\"âœ… Autentisert!\")\n",
    "else:\n",
    "    print(\"â­ï¸  Hopper over - kjÃ¸rer lokalt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“¦ Installer pakker (kun hvis nÃ¸dvendig)\n",
    "\n",
    "**Lokal**: Bruk `pip install -r requirements.txt` i terminalen  \n",
    "**Colab**: Allerede installert i tidligere celle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tips: Installer heller fra requirements.txt i terminalen:\n",
      "   pip install -r requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Installer pakker manuelt (kun hvis ikke installert via requirements.txt eller Colab)\n",
    "if not IN_COLAB:\n",
    "    print(\"ğŸ’¡ Tips: Installer fra requirements.txt i terminalen:\")\n",
    "    print(\"   pip install -r requirements.txt\")\n",
    "    print(\"\\nâ­ï¸  Hopper over automatisk installasjon lokalt\")\n",
    "else:\n",
    "    print(\"âœ… Pakker allerede installert i Colab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Alle biblioteker importert!\n"
     ]
    }
   ],
   "source": [
    "# Import biblioteker\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# PDF og teksthÃ¥ndtering\n",
    "import pymupdf4llm\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# GCP\n",
    "from google.cloud import secretmanager\n",
    "from google import genai\n",
    "\n",
    "# Database\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "print(\"âœ… Alle biblioteker importert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfigurer GCP-tilkobling\n",
    "\n",
    "Vi setter opp tilkobling til GCP-prosjektet vÃ¥rt og henter database-passordet fra Secret Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¿½ï¿½ Prosjekt: data-science-faggruppe-rag\n",
      "ğŸ“ Region: europe-west1\n",
      "ğŸ“ Database: vector_db\n"
     ]
    }
   ],
   "source": [
    "# GCP konfigurasjon\n",
    "PROJECT_ID = \"data-science-faggruppe-rag\"\n",
    "REGION = \"europe-west1\"\n",
    "SECRET_NAME = \"postgres-password\"\n",
    "\n",
    "# Cloud SQL konfigurasjon (fra terraform)\n",
    "DB_INSTANCE_NAME = \"vector-db-instance\"\n",
    "DB_NAME = \"vector_db\"\n",
    "DB_USER = \"postgres\"\n",
    "\n",
    "print(f\"ï¿½ï¿½ Prosjekt: {PROJECT_ID}\")\n",
    "print(f\"ğŸ“ Region: {REGION}\")\n",
    "print(f\"ğŸ“ Database: {DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database-passord hentet fra Secret Manager\n"
     ]
    }
   ],
   "source": [
    "# Hent database-passord fra Secret Manager\n",
    "def get_secret(project_id: str, secret_id: str, version_id: str = \"latest\") -> str:\n",
    "    \"\"\"\n",
    "    Hent secret fra Google Secret Manager.\n",
    "    \n",
    "    Args:\n",
    "        project_id: GCP prosjekt ID\n",
    "        secret_id: Secret navn\n",
    "        version_id: Versjon (default: latest)\n",
    "    \n",
    "    Returns:\n",
    "        Secret verdi som string\n",
    "    \"\"\"\n",
    "    client = secretmanager.SecretManagerServiceClient()\n",
    "    name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
    "    response = client.access_secret_version(request={\"name\": name})\n",
    "    return response.payload.data.decode(\"UTF-8\")\n",
    "\n",
    "# Hent passord\n",
    "DB_PASSWORD = get_secret(PROJECT_ID, SECRET_NAME)\n",
    "print(\"âœ… Database-passord hentet fra Secret Manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ğŸ’¡ Sikkerhetsmerknad:** Vi bruker Secret Manager for Ã¥ unngÃ¥ Ã¥ hardkode passord i koden. Dette er best practice for produksjonssystemer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cloud SQL IP hentet automatisk: 35.205.154.230\n",
      "\n",
      "ğŸ”— Database host: 35.205.154.230\n"
     ]
    }
   ],
   "source": [
    "# Hent Cloud SQL IP automatisk\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # PrÃ¸v Ã¥ hente IP fra gcloud\n",
    "    result = subprocess.run(\n",
    "        ['gcloud', 'sql', 'instances', 'describe', DB_INSTANCE_NAME,\n",
    "         '--format=value(ipAddresses[0].ipAddress)'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        DB_HOST = result.stdout.strip()\n",
    "        print(f\"âœ… Cloud SQL IP hentet automatisk: {DB_HOST}\")\n",
    "    else:\n",
    "        # Fallback: Manuell input\n",
    "        print(\"âš ï¸  Kunne ikke hente IP automatisk\")\n",
    "        print(f\"   Error: {result.stderr}\")\n",
    "        DB_HOST = input(\"Vennligst skriv inn Cloud SQL IP: \")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸  gcloud CLI ikke funnet\")\n",
    "    print(\"ğŸ’¡ Alternativ 1: Installer gcloud CLI\")\n",
    "    print(\"ğŸ’¡ Alternativ 2: Skriv inn IP manuelt\")\n",
    "    DB_HOST = input(\"Cloud SQL IP: \")\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"âš ï¸  Timeout ved henting av IP\")\n",
    "    DB_HOST = input(\"Cloud SQL IP: \")\n",
    "\n",
    "print(f\"\\nğŸ”— Database host: {DB_HOST}\")\n",
    "\n",
    "# Alternativ: Cloud SQL Proxy (hvis du bruker det)\n",
    "# DB_HOST = \"127.0.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Last inn og forbered dokument\n",
    "\n",
    "Vi bruker **Dokumentavgift 2025** som kunnskapsbase. Dette er et enklere dokument enn statsbudsjettet, perfekt for Ã¥ komme i gang!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Ekstraherer tekst fra PDF...\n",
      "\n",
      "âœ… PDF ekstrahert!\n",
      "ğŸ“Š Statistikk:\n",
      "   - Tegn: 66,598\n",
      "   - Linjer: 1,109\n",
      "   - Ord: 8,503\n",
      "\n",
      "================================================================================\n",
      "Utdrag fra dokumentet:\n",
      "================================================================================\n",
      "## **Ã…RSRUNDSKRIV FOR**\n",
      "# **DOKUMENTAVGIFT** **2025**\n",
      "\n",
      "1. januar 2025\n",
      "\n",
      "#### **Skattedirektoratet**\n",
      "\n",
      "Juridisk avdeling\n",
      "Postboks 9200 GrÃ¸nland\n",
      "\n",
      "0134 OSLO\n",
      "www.skatteetaten.no\n",
      "\n",
      "\n",
      "### **Innhold**\n",
      "\n",
      "1 Innledning .......................................................................................................................................... 4\n",
      "\n",
      "\n",
      "1.1 Om Skattedirektoratets Ã¥rsrundskriv ........................................................................................ 4\n",
      "\n",
      "\n",
      "1.2 Hva er dokumenta...\n",
      "\n",
      "âœ… PDF ekstrahert!\n",
      "ğŸ“Š Statistikk:\n",
      "   - Tegn: 66,598\n",
      "   - Linjer: 1,109\n",
      "   - Ord: 8,503\n",
      "\n",
      "================================================================================\n",
      "Utdrag fra dokumentet:\n",
      "================================================================================\n",
      "## **Ã…RSRUNDSKRIV FOR**\n",
      "# **DOKUMENTAVGIFT** **2025**\n",
      "\n",
      "1. januar 2025\n",
      "\n",
      "#### **Skattedirektoratet**\n",
      "\n",
      "Juridisk avdeling\n",
      "Postboks 9200 GrÃ¸nland\n",
      "\n",
      "0134 OSLO\n",
      "www.skatteetaten.no\n",
      "\n",
      "\n",
      "### **Innhold**\n",
      "\n",
      "1 Innledning .......................................................................................................................................... 4\n",
      "\n",
      "\n",
      "1.1 Om Skattedirektoratets Ã¥rsrundskriv ........................................................................................ 4\n",
      "\n",
      "\n",
      "1.2 Hva er dokumenta...\n"
     ]
    }
   ],
   "source": [
    "# Last inn PDF og konverter til Markdown\n",
    "if IN_COLAB:\n",
    "    pdf_path = \"dokumentavgift-2025.pdf\"  # Opplastet fil i Colab\n",
    "else:\n",
    "    pdf_path = \"../../data/dokumentavgift-2025.pdf\"  # Lokal sti\n",
    "\n",
    "print(\"ğŸ“„ Ekstraherer tekst fra PDF...\")\n",
    "document_text = pymupdf4llm.to_markdown(pdf_path)\n",
    "\n",
    "print(f\"\\nâœ… PDF ekstrahert!\")\n",
    "print(f\"ğŸ“Š Statistikk:\")\n",
    "print(f\"   - Tegn: {len(document_text):,}\")\n",
    "print(f\"   - Linjer: {len(document_text.splitlines()):,}\")\n",
    "print(f\"   - Ord: {len(document_text.split()):,}\")\n",
    "\n",
    "# Vis et utdrag\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Utdrag fra dokumentet:\")\n",
    "print(\"=\"*80)\n",
    "print(document_text[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking - Del opp dokumentet\n",
    "\n",
    "Vi deler dokumentet i mindre chunks som passer for embedding og retrieval.\n",
    "\n",
    "**Hvorfor chunking?**\n",
    "- ğŸ“ **Token-begrensninger**: Embedding-modeller har maks input-lengde\n",
    "- ğŸ¯ **Presisjon**: Mindre chunks gir mer presise sÃ¸keresultater\n",
    "- ğŸ’° **Kostnad**: Mindre context til LLM = lavere kostnader\n",
    "\n",
    "Vi bruker LangChains `CharacterTextSplitter` som deler pÃ¥ dobbel-newline (paragrafer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dokumentet delt i 84 chunks\n",
      "\n",
      "ğŸ“Š Chunk-statistikk:\n",
      "   - Gjennomsnitt: 791 tegn\n",
      "   - Min: 141 tegn\n",
      "   - Max: 998 tegn\n",
      "\n",
      "ğŸ” Chunks som inneholder 'hva er dokumentavgift':\n",
      "\n",
      "================================================================================\n",
      "CHUNK 0 (914 tegn):\n",
      "================================================================================\n",
      "## **Ã…RSRUNDSKRIV FOR**\n",
      "# **DOKUMENTAVGIFT** **2025**\n",
      "\n",
      "1. januar 2025\n",
      "\n",
      "#### **Skattedirektoratet**\n",
      "\n",
      "Juridisk avdeling\n",
      "Postboks 9200 GrÃ¸nland\n",
      "\n",
      "0134 OSLO\n",
      "www.skatteetaten.no\n",
      "\n",
      "\n",
      "### **Innhold**\n",
      "\n",
      "1 Innledning .......................................................................................................................................... 4\n",
      "\n",
      "\n",
      "1.1 Om Skattedirektoratets Ã¥rsrundskriv ........................................................................................ 4\n",
      "\n",
      "\n",
      "1.2 Hva er dokumentavgift? ........................................................................................................... 4\n",
      "\n",
      "\n",
      "1.3 Hvilket regelverk gjelder? ......................................................................................................... 4\n",
      "\n",
      "\n",
      "2 Avgiftsplikt .........................\n",
      "\n",
      "... (resten kuttet for lesbarhet)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CHUNK 7 (633 tegn):\n",
      "================================================================================\n",
      "### **1 Innledning**\n",
      "#### **1.1 Om Skattedirektoratets Ã¥rsrundskriv**\n",
      "\n",
      "Ã…rsrundskriv for dokumentavgift er utarbeidet av Skattedirektoratet, og gir en nÃ¦rmere redegjÃ¸relse\n",
      "for relevante bestemmelser i dokumentavgiftsregelverket.\n",
      "\n",
      "MÃ¥lgruppen for Ã¥rsrundskrivet er skattemyndighetene og de avgiftspliktige, men det kan ogsÃ¥ ha\n",
      "interesse for andre som Ã¸nsker informasjon om regelverket.\n",
      "\n",
      "Skattedirektoratets Ã¥rsrundskriv for dokumentavgift oppdateres Ã¥rlig med de endringer Stortinget\n",
      "vedtar i forbindelse med statsbudsjettet. Ã…rsrundskrivet oppdateres ogsÃ¥ i lÃ¸pet av Ã¥ret hvis det er\n",
      "behov for det.\n",
      "\n",
      "#### **1.2 Hva er dokumentavgift?**\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],        # Del pÃ¥ dobbel-newline (paragraf)\n",
    "    chunk_size=1000,         # Stor nok for hele avsnitt\n",
    "    chunk_overlap=0,       # Overlap for kontekst\n",
    ")\n",
    "\n",
    "# Del opp dokumentet\n",
    "chunks = text_splitter.create_documents([document_text])\n",
    "\n",
    "print(f\"âœ… Dokumentet delt i {len(chunks)} chunks\")\n",
    "print(f\"\\nğŸ“Š Chunk-statistikk:\")\n",
    "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "print(f\"   - Gjennomsnitt: {sum(chunk_lengths)/len(chunk_lengths):.0f} tegn\")\n",
    "print(f\"   - Min: {min(chunk_lengths)} tegn\")\n",
    "print(f\"   - Max: {max(chunk_lengths)} tegn\")\n",
    "\n",
    "# Vis chunks som inneholder \"dokumentavgift\"\n",
    "print(f\"\\nğŸ” Chunks som inneholder 'hva er dokumentavgift':\")\n",
    "relevant_chunks = [\n",
    "    (idx, chunk) for idx, chunk in enumerate(chunks) \n",
    "    if 'hva er dokumentavgift' in chunk.page_content.lower()\n",
    "]\n",
    "\n",
    "for idx, chunk in relevant_chunks[:3]:  # Vis maks 3\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CHUNK {idx} ({len(chunk.page_content)} tegn):\")\n",
    "    print('='*80)\n",
    "    print(chunk.page_content[:800])  # Vis fÃ¸rste 800 tegn\n",
    "    if len(chunk.page_content) > 800:\n",
    "        print(\"\\n... (resten kuttet for lesbarhet)\")\n",
    "    print('='*80)\n",
    "\n",
    "if not relevant_chunks:\n",
    "    print(\"  âš ï¸  Ingen chunks funnet med 'hva er dokumentavgift'\")\n",
    "    print(\"\\nğŸ“„ Viser i stedet fÃ¸rste 2 chunks:\")\n",
    "    for idx in range(min(2, len(chunks))):\n",
    "        print(f\"\\nCHUNK {idx}: {chunks[idx].page_content[:400]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vertex AI - Embeddings og LLM\n",
    "\n",
    "Vi bruker Google Vertex AI for:\n",
    "- **Embeddings**: `text-embedding-004` (768 dimensjoner)\n",
    "- **Generation**: `gemini-2.0-flash-001` (rask og kostnadseffektiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vertex AI konfigurert!\n",
      "   Project: data-science-faggruppe-rag\n",
      "   Region: europe-west1\n",
      "   Models: text-multilingual-embedding-002, gemini-2.0-flash-001\n"
     ]
    }
   ],
   "source": [
    "# Konfigurer Vertex AI\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(\"âœ… Vertex AI konfigurert!\")\n",
    "print(f\"   Project: {PROJECT_ID}\")\n",
    "print(f\"   Region: {REGION}\")\n",
    "print(f\"   Models: text-multilingual-embedding-002, gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding generert!\n",
      "   - Dimensjoner: 768\n",
      "   - Type: <class 'float'>\n",
      "   - FÃ¸rste 5 verdier: [0.009539585560560226, -0.028674542903900146, -0.03958906978368759, 0.03002873621881008, 0.021501852199435234]\n"
     ]
    }
   ],
   "source": [
    "# Funksjon for Ã¥ generere embeddings\n",
    "def get_embedding(text: str, task_type: str = 'RETRIEVAL_DOCUMENT') -> List[float]:\n",
    "    \"\"\"\n",
    "    Generer embedding for tekst ved hjelp av Vertex AI.\n",
    "    \n",
    "    Args:\n",
    "        text: Tekst Ã¥ embedde\n",
    "        task_type: 'RETRIEVAL_DOCUMENT' for dokumenter, 'RETRIEVAL_QUERY' for sÃ¸k\n",
    "    \n",
    "    Returns:\n",
    "        Liste med floats (embedding-vektor)\n",
    "    \"\"\"\n",
    "    client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)\n",
    "    response = client.models.embed_content(\n",
    "        model='text-multilingual-embedding-002',\n",
    "        contents=text,\n",
    "        config={'task_type': task_type}\n",
    "    )\n",
    "    return response.embeddings[0].values\n",
    "\n",
    "# Test embedding-generering\n",
    "test_text = \"Dette er en test av embedding-funksjonen.\"\n",
    "test_embedding = get_embedding(test_text)\n",
    "\n",
    "print(f\"âœ… Embedding generert!\")\n",
    "print(f\"   - Dimensjoner: {len(test_embedding)}\")\n",
    "print(f\"   - Type: {type(test_embedding[0])}\")\n",
    "print(f\"   - FÃ¸rste 5 verdier: {test_embedding[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cloud SQL - Vector Database\n",
    "\n",
    "Vi kobler til Cloud SQL PostgreSQL med pgvector-extension for Ã¥ lagre og sÃ¸ke i embeddings.\n",
    "\n",
    "**pgvector** er en PostgreSQL-extension som gir:\n",
    "- âš¡ Rask similarity search\n",
    "- ğŸ“Š StÃ¸tte for forskjellige distance metrics (L2, cosine, inner product)\n",
    "- ğŸ” HNSW og IVFFlat indekser for skalerbarhet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tilkoblet Cloud SQL!\n",
      "   PostgreSQL versjon: PostgreSQL 15.15 on x86_64-pc-linux-gnu, compiled ...\n"
     ]
    }
   ],
   "source": [
    "# Koble til Cloud SQL\n",
    "def get_db_connection():\n",
    "    \"\"\"\n",
    "    Opprett tilkobling til Cloud SQL PostgreSQL.\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        port=5432\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# Test tilkobling\n",
    "try:\n",
    "    conn = get_db_connection()\n",
    "    register_vector(conn)  # Registrer pgvector-typer\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT version();\")\n",
    "    version = cur.fetchone()\n",
    "    \n",
    "    print(\"âœ… Tilkoblet Cloud SQL!\")\n",
    "    print(f\"   PostgreSQL versjon: {version[0][:50]}...\")\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Feil ved tilkobling: {e}\")\n",
    "    print(\"\\nğŸ’¡ Sjekk at:\")\n",
    "    print(\"   1. DB_HOST er satt til riktig IP\")\n",
    "    print(\"   2. Cloud SQL instance er oppe\")\n",
    "    print(\"   3. Firewall-regler tillater tilkobling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tabell 'document_chunks' opprettet med pgvector index!\n"
     ]
    }
   ],
   "source": [
    "# Opprett tabell for chunks med embeddings\n",
    "def create_chunks_table():\n",
    "    \"\"\"\n",
    "    Opprett tabell for Ã¥ lagre document chunks med embeddings.\n",
    "    \"\"\"\n",
    "    conn = get_db_connection()\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Drop eksisterende tabell (for workshop-formÃ¥l)\n",
    "    cur.execute(\"DROP TABLE IF EXISTS document_chunks;\")\n",
    "    \n",
    "    # Opprett ny tabell\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE document_chunks (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            content TEXT NOT NULL,\n",
    "            embedding vector(768),  -- text-embedding-004 har 768 dimensjoner\n",
    "            metadata JSONB,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Opprett index for raskere similarity search\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE INDEX ON document_chunks \n",
    "        USING ivfflat (embedding vector_cosine_ops)\n",
    "        WITH (lists = 100);\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"âœ… Tabell 'document_chunks' opprettet med pgvector index!\")\n",
    "\n",
    "# Opprett tabell\n",
    "create_chunks_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generer embeddings og lagre i database\n",
    "\n",
    "NÃ¥ genererer vi embeddings for alle chunks og lagrer dem i Cloud SQL. Dette kan ta noen minutter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Prosesserer 84 chunks...\n",
      "\n",
      "   âœ“ Prosessert 10/84 chunks\n",
      "   âœ“ Prosessert 10/84 chunks\n",
      "   âœ“ Prosessert 20/84 chunks\n",
      "   âœ“ Prosessert 20/84 chunks\n",
      "   âœ“ Prosessert 30/84 chunks\n",
      "   âœ“ Prosessert 30/84 chunks\n",
      "   âœ“ Prosessert 40/84 chunks\n",
      "   âœ“ Prosessert 40/84 chunks\n",
      "   âœ“ Prosessert 50/84 chunks\n",
      "   âœ“ Prosessert 50/84 chunks\n",
      "   âœ“ Prosessert 60/84 chunks\n",
      "   âœ“ Prosessert 60/84 chunks\n",
      "   âœ“ Prosessert 70/84 chunks\n",
      "   âœ“ Prosessert 70/84 chunks\n",
      "   âœ“ Prosessert 80/84 chunks\n",
      "   âœ“ Prosessert 80/84 chunks\n",
      "\n",
      "âœ… Alle 84 chunks lagret i database!\n",
      "\n",
      "âœ… Alle 84 chunks lagret i database!\n"
     ]
    }
   ],
   "source": [
    "# Generer embeddings og lagre i database\n",
    "def insert_chunks_with_embeddings(chunks: List, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Generer embeddings for chunks og lagre i database.\n",
    "    \n",
    "    Args:\n",
    "        chunks: Liste med LangChain Document objekter\n",
    "        batch_size: Antall chunks Ã¥ prosessere samtidig\n",
    "    \"\"\"\n",
    "    conn = get_db_connection()\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    total = len(chunks)\n",
    "    print(f\"ğŸ”„ Prosesserer {total} chunks...\\n\")\n",
    "    \n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        \n",
    "        # Generer embeddings for batch\n",
    "        for idx, chunk in enumerate(batch):\n",
    "            global_idx = i + idx\n",
    "            \n",
    "            # Generer embedding\n",
    "            embedding = get_embedding(chunk.page_content)\n",
    "            \n",
    "            # Metadata\n",
    "            metadata = json.dumps({\n",
    "                \"chunk_index\": global_idx,\n",
    "                \"length\": len(chunk.page_content)\n",
    "            })\n",
    "            \n",
    "            # Insert i database\n",
    "            cur.execute(\n",
    "                \"INSERT INTO document_chunks (content, embedding, metadata) VALUES (%s, %s, %s)\",\n",
    "                (chunk.page_content, embedding, metadata)\n",
    "            )\n",
    "            \n",
    "            if (global_idx + 1) % 10 == 0:\n",
    "                print(f\"   âœ“ Prosessert {global_idx + 1}/{total} chunks\")\n",
    "        \n",
    "        conn.commit()\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\nâœ… Alle {total} chunks lagret i database!\")\n",
    "\n",
    "# Lagre chunks\n",
    "insert_chunks_with_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Database-statistikk:\n",
      "   - Antall chunks: 84\n",
      "\n",
      "ğŸ“„ Eksempel pÃ¥ lagrede chunks:\n",
      "\n",
      "Chunk 1:\n",
      "   Metadata: {'length': 914, 'chunk_index': 0}\n",
      "   Content: ## **Ã…RSRUNDSKRIV FOR**\n",
      "# **DOKUMENTAVGIFT** **2025**\n",
      "\n",
      "1. januar 2025\n",
      "\n",
      "#### **Skattedirektoratet**\n",
      "\n",
      "...\n",
      "\n",
      "Chunk 2:\n",
      "   Metadata: {'length': 969, 'chunk_index': 1}\n",
      "   Content: 2.1 Avgiftspliktens omfang ............................................................................\n",
      "\n",
      "Chunk 3:\n",
      "   Metadata: {'length': 969, 'chunk_index': 2}\n",
      "   Content: 3.4 RegisterfÃ¸rerens fastsettelse av avgiftsgrunnlaget â€“ \"Ã¥penbart for lavt\" ..........................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifiser data i database\n",
    "conn = get_db_connection()\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM document_chunks;\")\n",
    "count = cur.fetchone()[0]\n",
    "\n",
    "cur.execute(\"SELECT content, metadata FROM document_chunks LIMIT 3;\")\n",
    "samples = cur.fetchall()\n",
    "\n",
    "print(f\"ğŸ“Š Database-statistikk:\")\n",
    "print(f\"   - Antall chunks: {count}\")\n",
    "print(f\"\\nğŸ“„ Eksempel pÃ¥ lagrede chunks:\\n\")\n",
    "\n",
    "for i, (content, metadata) in enumerate(samples, 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(f\"   Metadata: {metadata}\")\n",
    "    print(f\"   Content: {content[:100]}...\")\n",
    "    print()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieval - SÃ¸k etter relevante chunks\n",
    "\n",
    "NÃ¥ kan vi sÃ¸ke i vector database med semantic search!\n",
    "\n",
    "**Slik fungerer det:**\n",
    "1. Konverter brukerens spÃ¸rsmÃ¥l til embedding\n",
    "2. SÃ¸k etter chunks med mest lignende embeddings (cosine similarity)\n",
    "3. Returner topp-k mest relevante chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” SÃ¸k: 'Hva er dokumentavgift?'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Resultat 1 (Similarity: 0.7768):\n",
      "--------------------------------------------------------------------------------\n",
      "Lengde: 911 tegn\n",
      "Innhold: _[(dal. Â§ 7](https://lovdata.no/lov/1975-12-12-59/Â§7)_ _femte ledd annet punktum)_\n",
      "Ved offentlig jordskifte skal dokumentavgiften beregnes som ved opplÃ¸sning av sameie (se punkt 4.4),\n",
      "jf. dal. Â§ 7 femte ledd annet punktum. Dette innebÃ¦rer at avgiften beregnes av verdiforskyvningen\n",
      "innenfor jordskifteomrÃ¥det, sett under ett.\n",
      "\n",
      "#### **4.16 Annet**\n",
      "\n",
      "_[(helseforetaksloven Â§ 50](https://lovdata.no/lov/2001-06-15-93/Â§50)_ _tredje ledd og_ _[inndelingsloven Â§ 14)](https://lovdata.no/lov/2001-06-15-70/Â§1...\n",
      "================================================================================\n",
      "\n",
      "Resultat 2 (Similarity: 0.7157):\n",
      "--------------------------------------------------------------------------------\n",
      "Lengde: 980 tegn\n",
      "Innhold: PÃ¥ denne bakgrunn refunderes betalt dokumentavgift nÃ¥r det foreligger rettskraftig dom eller rettsforlik\n",
      "som kjenner dokumentbeskrevet rettsstiftelse ugyldig fra fÃ¸rst av. Ugyldigheten mÃ¥ vÃ¦re relatert til\n",
      "avtalen. Det er imidlertid ikke et absolutt vilkÃ¥r at forliket er inngÃ¥tt for en domstol. Det avgjÃ¸rende er\n",
      "om det kan dokumenteres pÃ¥ behÃ¸rig mÃ¥te at rettsstiftelsen var ugyldig fra fÃ¸rst av. I saker med forlik\n",
      "mÃ¥ det derfor, uansett formulering i forliket vurderes om overdragelsen var ugyldi...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# SÃ¸kefunksjon\n",
    "def search_similar_chunks(query: str, top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    SÃ¸k etter lignende chunks basert pÃ¥ query.\n",
    "    \n",
    "    Args:\n",
    "        query: SÃ¸kestreng\n",
    "        top_k: Antall resultater Ã¥ returnere\n",
    "    \n",
    "    Returns:\n",
    "        Liste med relevante chunks og similarity scores\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query, task_type='RETRIEVAL_QUERY')\n",
    "    \n",
    "    # SÃ¸k i database\n",
    "    conn = get_db_connection()\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            id,\n",
    "            content,\n",
    "            metadata,\n",
    "            1 - (embedding <=> %s::vector) as similarity\n",
    "        FROM document_chunks\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT %s;\n",
    "        \"\"\",\n",
    "        (query_embedding, query_embedding, top_k)\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for row in cur.fetchall():\n",
    "        results.append({\n",
    "            'id': row[0],\n",
    "            'content': row[1],\n",
    "            'metadata': row[2],\n",
    "            'similarity': float(row[3])\n",
    "        })\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test sÃ¸k\n",
    "test_query = \"Hva er dokumentavgift?\"\n",
    "results = search_similar_chunks(test_query, top_k=3)\n",
    "\n",
    "print(f\"ğŸ” SÃ¸k: '{test_query}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not results:\n",
    "    print(\"âš ï¸  Ingen resultater funnet! Sjekk at databasen inneholder data.\")\n",
    "else:\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nResultat {i} (Similarity: {result['similarity']:.4f}):\")\n",
    "        print(\"-\"*80)\n",
    "        print(f\"Lengde: {len(result['content'])} tegn\")\n",
    "        print(f\"Innhold: {result['content'][:500]}...\")\n",
    "        print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generation - Generer svar med Gemini\n",
    "\n",
    "Siste steg: Kombiner retrieved chunks med brukerens spÃ¸rsmÃ¥l og bruk Gemini til Ã¥ generere et svar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ SpÃ¸rsmÃ¥l: Hva er dokumentavgift?\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ Svar:\n",
      "================================================================================\n",
      "Konteksten gir ikke en direkte definisjon av hva dokumentavgift er.\n",
      "\n",
      "Imidlertid fremgÃ¥r det at det er en avgift som:\n",
      "*   Beregnes ved offentlig jordskifte, basert pÃ¥ verdiforskyvningen (Kilde 1).\n",
      "*   Vanligvis skal betales for overfÃ¸ringer i grunnboken og tinglysing av overfÃ¸ringer, med visse unntak som for overfÃ¸ringer etter helseforetaksloven og grenseendringer etter inndelingsloven (Kilde 1).\n",
      "*   Kan refunderes dersom en dokumentert rettsstiftelse kjennes ugyldig, eller der et eldre rettserverv gÃ¥r foran et yngre (Kilde 2).\n"
     ]
    }
   ],
   "source": [
    "# Genereringsfunksjon\n",
    "def generate_answer(query: str, context_chunks: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Generer svar basert pÃ¥ query og context.\n",
    "    \n",
    "    Args:\n",
    "        query: Brukerens spÃ¸rsmÃ¥l\n",
    "        context_chunks: Relevante chunks fra retrieval\n",
    "    \n",
    "    Returns:\n",
    "        Generert svar\n",
    "    \"\"\"\n",
    "    # Bygg context fra chunks\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[Kilde {i+1}]\\n{chunk['content']}\" \n",
    "        for i, chunk in enumerate(context_chunks)\n",
    "    ])\n",
    "    \n",
    "    # Bygg prompt\n",
    "    prompt = f\"\"\"Du er en hjelpsom assistent som svarer pÃ¥ spÃ¸rsmÃ¥l om dokumentavgift basert pÃ¥ norsk regelverk.\n",
    "\n",
    "Svar pÃ¥ spÃ¸rsmÃ¥let basert pÃ¥ konteksten nedenfor. Hvis konteksten ikke inneholder nok informasjon til Ã¥ gi et komplett svar, gi et delvis svar basert pÃ¥ det som er tilgjengelig.\n",
    "\n",
    "KONTEKST:\n",
    "{context}\n",
    "\n",
    "SPÃ˜RSMÃ…L: {query}\n",
    "\n",
    "SVAR:\"\"\"\n",
    "    \n",
    "    # Generer svar med Gemini\n",
    "    client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# Test generering\n",
    "answer = generate_answer(test_query, results)\n",
    "\n",
    "print(f\"â“ SpÃ¸rsmÃ¥l: {test_query}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“ Svar:\")\n",
    "print(\"=\"*80)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Komplett RAG Pipeline\n",
    "\n",
    "La oss pakke alt sammen i Ã©n funksjon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” SÃ¸ker etter relevante chunks...\n",
      "âœ“ Fant 2 relevante chunks\n",
      "ğŸ¤– Genererer svar...\n",
      "âœ“ Fant 2 relevante chunks\n",
      "ğŸ¤– Genererer svar...\n",
      "âœ“ Svar generert!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â“ Hva er dokumentavgift?\n",
      "\n",
      "ğŸ“ Konteksten gir ikke en direkte definisjon av hva dokumentavgift er.\n",
      "\n",
      "Basert pÃ¥ informasjonen kan det likevel utledes at dokumentavgift er en avgift som:\n",
      "*   **Beregningsgrunnlag:** I visse tilfeller, som ved offentlig jordskifte, beregnes den av verdiforskyvningen innenfor jordskifteomrÃ¥det.\n",
      "*   **AnvendelsesomrÃ¥de:** Den nevnes i forbindelse med overfÃ¸ringer i grunnboken og tinglysing av overfÃ¸ringer.\n",
      "*   **Unntak:** Det skal ikke betales dokumentavgift for overfÃ¸ringer i grunnboken som foretas i medhold av helseforetaksloven, eller for tinglysing av overfÃ¸ringer som er en direkte fÃ¸lge av grenseendringer etter inndelingsloven.\n",
      "*   **Refusjon:** Betalt dokumentavgift kan refunderes under spesielle omstendigheter, for eksempel nÃ¥r en rettsstiftelse kjennes ugyldig eller et eldre rettserverv gÃ¥r foran et yngre.\n",
      "\n",
      "ğŸ“š Basert pÃ¥ 2 kilder\n",
      "\n",
      "================================================================================\n",
      "ğŸ” SÃ¸ker etter relevante chunks...\n",
      "âœ“ Svar generert!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â“ Hva er dokumentavgift?\n",
      "\n",
      "ğŸ“ Konteksten gir ikke en direkte definisjon av hva dokumentavgift er.\n",
      "\n",
      "Basert pÃ¥ informasjonen kan det likevel utledes at dokumentavgift er en avgift som:\n",
      "*   **Beregningsgrunnlag:** I visse tilfeller, som ved offentlig jordskifte, beregnes den av verdiforskyvningen innenfor jordskifteomrÃ¥det.\n",
      "*   **AnvendelsesomrÃ¥de:** Den nevnes i forbindelse med overfÃ¸ringer i grunnboken og tinglysing av overfÃ¸ringer.\n",
      "*   **Unntak:** Det skal ikke betales dokumentavgift for overfÃ¸ringer i grunnboken som foretas i medhold av helseforetaksloven, eller for tinglysing av overfÃ¸ringer som er en direkte fÃ¸lge av grenseendringer etter inndelingsloven.\n",
      "*   **Refusjon:** Betalt dokumentavgift kan refunderes under spesielle omstendigheter, for eksempel nÃ¥r en rettsstiftelse kjennes ugyldig eller et eldre rettserverv gÃ¥r foran et yngre.\n",
      "\n",
      "ğŸ“š Basert pÃ¥ 2 kilder\n",
      "\n",
      "================================================================================\n",
      "ğŸ” SÃ¸ker etter relevante chunks...\n",
      "âœ“ Fant 3 relevante chunks\n",
      "ğŸ¤– Genererer svar...\n",
      "âœ“ Fant 3 relevante chunks\n",
      "ğŸ¤– Genererer svar...\n",
      "âœ“ Svar generert!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â“ Hvem mÃ¥ betale dokumentavgift?\n",
      "\n",
      "ğŸ“ Basert pÃ¥ konteksten, nevnes det at dokumentavgiften skal betales ved tinglysing av dokument som overfÃ¸rer hjemmel til fast eiendom. Konteksten spesifiserer ikke direkte *hvem* som er pliktig til Ã¥ betale avgiften. Den refererer til \"de avgiftspliktige\" som en mÃ¥lgruppe for Skattedirektoratets rundskriv, men definerer ikke nÃ¦rmere hvem disse er i praksis.\n",
      "\n",
      "ğŸ“š Basert pÃ¥ 3 kilder\n",
      "\n",
      "================================================================================\n",
      "ğŸ” SÃ¸ker etter relevante chunks...\n",
      "âœ“ Svar generert!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â“ Hvem mÃ¥ betale dokumentavgift?\n",
      "\n",
      "ğŸ“ Basert pÃ¥ konteksten, nevnes det at dokumentavgiften skal betales ved tinglysing av dokument som overfÃ¸rer hjemmel til fast eiendom. Konteksten spesifiserer ikke direkte *hvem* som er pliktig til Ã¥ betale avgiften. Den refererer til \"de avgiftspliktige\" som en mÃ¥lgruppe for Skattedirektoratets rundskriv, men definerer ikke nÃ¦rmere hvem disse er i praksis.\n",
      "\n",
      "ğŸ“š Basert pÃ¥ 3 kilder\n",
      "\n",
      "================================================================================\n",
      "ğŸ” SÃ¸ker etter relevante chunks...\n",
      "âœ“ Fant 3 relevante chunks\n",
      "ğŸ¤– Genererer svar...\n",
      "âœ“ Fant 3 relevante chunks\n",
      "ğŸ¤– Genererer svar...\n",
      "âœ“ Svar generert!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â“ Hva er avgiftssatsen for dokumentavgift?\n",
      "\n",
      "ğŸ“ Avgiftssatsen for dokumentavgift utgjÃ¸r 2,5 prosent av eiendommens salgsverdi.\n",
      "\n",
      "ğŸ“š Basert pÃ¥ 3 kilder\n",
      "âœ“ Svar generert!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "â“ Hva er avgiftssatsen for dokumentavgift?\n",
      "\n",
      "ğŸ“ Avgiftssatsen for dokumentavgift utgjÃ¸r 2,5 prosent av eiendommens salgsverdi.\n",
      "\n",
      "ğŸ“š Basert pÃ¥ 3 kilder\n"
     ]
    }
   ],
   "source": [
    "# Komplett RAG pipeline\n",
    "def rag_query(query: str, top_k: int = 5) -> Dict:\n",
    "    \"\"\"\n",
    "    Komplett RAG pipeline: Retrieve + Generate.\n",
    "    \n",
    "    Args:\n",
    "        query: Brukerens spÃ¸rsmÃ¥l\n",
    "        top_k: Antall chunks Ã¥ hente\n",
    "    \n",
    "    Returns:\n",
    "        Dict med query, answer, og sources\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” SÃ¸ker etter relevante chunks...\")\n",
    "    chunks = search_similar_chunks(query, top_k=top_k)\n",
    "    \n",
    "    print(f\"âœ“ Fant {len(chunks)} relevante chunks\")\n",
    "    print(f\"ğŸ¤– Genererer svar...\")\n",
    "    \n",
    "    answer = generate_answer(query, chunks)\n",
    "    \n",
    "    print(f\"âœ“ Svar generert!\\n\")\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'answer': answer,\n",
    "        'sources': chunks\n",
    "    }\n",
    "\n",
    "# Test med flere spÃ¸rsmÃ¥l\n",
    "queries = [\n",
    "    \"Hva er dokumentavgift?\",\n",
    "    \"Hvem mÃ¥ betale dokumentavgift?\",\n",
    "    \"Hva er avgiftssatsen for dokumentavgift?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    result = rag_query(query, top_k=3)\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nâ“ {result['query']}\")\n",
    "    print(f\"\\nğŸ“ {result['answer']}\")\n",
    "    print(f\"\\nğŸ“š Basert pÃ¥ {len(result['sources'])} kilder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Oppsummering\n",
    "\n",
    "Gratulerer! Du har nÃ¥ bygget et komplett RAG-system med:\n",
    "\n",
    "### âœ… Hva vi har lÃ¦rt\n",
    "\n",
    "1. **PDF-ekstraksjon** med pymupdf4llm\n",
    "2. **Chunking** med LangChain\n",
    "3. **Embeddings** med Vertex AI (text-embedding-004)\n",
    "4. **Vector database** med Cloud SQL + pgvector\n",
    "5. **Similarity search** med cosine distance\n",
    "6. **Answer generation** med Gemini 1.5 Flash\n",
    "7. **Secret management** med Google Secret Manager\n",
    "\n",
    "### ğŸš€ Neste steg\n",
    "\n",
    "I de neste delene av workshopen skal vi se pÃ¥:\n",
    "- **Avansert chunking**: Hierarkisk og semantisk chunking\n",
    "- **Hybrid search**: Kombinere vector search med keyword search\n",
    "- **Re-ranking**: Forbedre retrieved chunks\n",
    "- **Evaluering**: MÃ¥le kvalitet pÃ¥ RAG-systemet\n",
    "\n",
    "### ğŸ’¡ Tips for produksjon\n",
    "\n",
    "- ğŸ”’ Bruk private IP for Cloud SQL\n",
    "- ğŸ“Š Implementer logging og monitoring\n",
    "- âš¡ Optimaliser med batch processing\n",
    "- ğŸ§ª Test med forskjellige embedding-modeller\n",
    "- ï¿½ï¿½ Skaler med stÃ¸rre vector indexes (HNSW)\n",
    "\n",
    "**Lykke til videre!** ï¿½ï¿½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¾ Checkpoint - Eksporter data for neste notebook\n",
    "\n",
    "FÃ¸r du gÃ¥r videre til neste del av workshopen, eksporter data slik at du kan fortsette der du slapp!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksporter checkpoint til JSON for neste notebook\n",
    "checkpoint_data = {\n",
    "    'project_id': PROJECT_ID,\n",
    "    'region': REGION,\n",
    "    'db_config': {\n",
    "        'host': DB_HOST,\n",
    "        'database': DB_NAME,\n",
    "        'user': DB_USER,\n",
    "        # Passord lastes fra Secret Manager i neste notebook\n",
    "    },\n",
    "    'document': {\n",
    "        'name': 'Dokumentavgift 2025',\n",
    "        'path': pdf_path,\n",
    "        'total_chunks': len(chunks),\n",
    "        'text_length': len(document_text)\n",
    "    },\n",
    "    'embeddings': {\n",
    "        'model': 'text-multilingual-embedding-002',\n",
    "        'dimensions': 768\n",
    "    },\n",
    "    'chunks_in_db': True\n",
    "}\n",
    "\n",
    "# Lagre checkpoint\n",
    "checkpoint_file = 'workshop_checkpoint.json'\n",
    "with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… Checkpoint lagret: {checkpoint_file}\")\n",
    "print(f\"\\nğŸ“Š Oppsummering:\")\n",
    "print(f\"   - Chunks i database: {checkpoint_data['document']['total_chunks']}\")\n",
    "print(f\"   - Embedding model: {checkpoint_data['embeddings']['model']}\")\n",
    "print(f\"   - Database: {checkpoint_data['db_config']['database']}\")\n",
    "print(f\"\\nğŸ’¡ Bruk denne filen til Ã¥ starte neste notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”œ Klar for neste steg?\n",
    "\n",
    "Du har nÃ¥:\n",
    "- âœ… Bygget en grunnleggende RAG pipeline\n",
    "- âœ… Lagret chunks med embeddings i Cloud SQL\n",
    "- âœ… Eksportert checkpoint-data\n",
    "\n",
    "**Neste notebooks:**\n",
    "\n",
    "1. **Chunking-strategier** (`chunking.ipynb`)\n",
    "   - Sammenlign forskjellige chunking-metoder\n",
    "   - Hierarkisk vs semantisk chunking\n",
    "   - Forbedre retrieval-kvalitet\n",
    "\n",
    "2. **Avansert sÃ¸k** \n",
    "   - Hybrid search (vector + keyword)\n",
    "   - Query rewriting\n",
    "   - Metadata filtering\n",
    "\n",
    "3. **Re-ranking og evaluering**\n",
    "   - Cross-encoder re-ranking\n",
    "   - RAG-spesifikke metrics\n",
    "   - KvalitetsmÃ¥ling\n",
    "\n",
    "**Start neste notebook med checkpoint-data:**\n",
    "```python\n",
    "import json\n",
    "with open('workshop_checkpoint.json', 'r') as f:\n",
    "    checkpoint = json.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Valgfri) Opprydding\n",
    "\n",
    "Hvis du vil slette data fra databasen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slett alle chunks (kjÃ¸r bare hvis du vil starte pÃ¥ nytt)\n",
    "# conn = get_db_connection()\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"DROP TABLE IF EXISTS document_chunks;\")\n",
    "# conn.commit()\n",
    "# cur.close()\n",
    "# conn.close()\n",
    "# print(\"âœ… Tabell slettet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
