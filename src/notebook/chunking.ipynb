{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer nÃ¸dvendige pakker\n",
    "# !pip install pymupdf4llm pymupdf requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e308e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ],
   "source": [
    "import pymupdf4llm\n",
    "import fitz\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32e5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_markdown(md: str) -> str:\n",
    "    \"\"\"Strip page numbers and clean spacing\"\"\"\n",
    "    md = re.sub(r\"(?m)^\\s*\\d+\\s*$\", \"\", md)  # remove number-only lines\n",
    "    md = re.sub(r\"\\n{3,}\", \"\\n\\n\", md)\n",
    "    return md.strip()\n",
    "    \n",
    "def extract_pdf_to_jsonl(\n",
    "    pdf_path: Path,\n",
    "    out_dir: Path,\n",
    "    source: str,\n",
    "    domain: str,\n",
    "    start_page: int = 0,\n",
    "    end_page: int | None = None,\n",
    "    source_type: str = \"pdf\",\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Konverter lokal PDF til markdown â†’ lagre som JSONL med metadata.\n",
    "    Returnerer sti til .jsonl-fila.\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Filnavn basert pÃ¥ tittel\n",
    "    slug = source.lower().replace(\" \", \"-\")\n",
    "    out_jsonl = out_dir / f\"{slug}.jsonl\"\n",
    "\n",
    "    # Finn antall sider\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        if end_page is None:\n",
    "            end_page = doc.page_count\n",
    "        print(f\"ðŸ“„ {doc.page_count} sider (leser {start_page+1}â€“{end_page})\")\n",
    "\n",
    "    # PDF â†’ Markdown\n",
    "    md_text = pymupdf4llm.to_markdown(str(pdf_path), pages=range(start_page, end_page))\n",
    "    md_text = clean_markdown(md_text)\n",
    "\n",
    "    # Lag JSON-record\n",
    "    record = {\n",
    "        \"source\": source,\n",
    "        \"domain\": domain,\n",
    "        \"source_url\": str(pdf_path),\n",
    "        \"source_type\": source_type,\n",
    "        \"text_format\": \"markdown\",\n",
    "        \"text\": md_text,\n",
    "        \"retrieved_at\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    }\n",
    "\n",
    "    # Skriv utfil\n",
    "    out_jsonl.write_text(json.dumps(record, ensure_ascii=False) + \"\\n\", encoding=\"utf-8\")\n",
    "    print(f\"ðŸ’¾ Skrev {out_jsonl}\")\n",
    "    return out_jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39297116",
   "metadata": {},
   "source": [
    "## KjÃ¸r konvertering av Statsbudsjett PDF\n",
    "\n",
    "Oppdater URL og metadata under for Ã¥ laste ned og konvertere statsbudsjett.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ 190 sider (leser 1â€“190)\n",
      "ðŸ’¾ Skrev output/statsbudsjett-2025.jsonl\n",
      "\n",
      "âœ… Ferdig! Output: output/statsbudsjett-2025.jsonl\n",
      "ðŸ’¾ Skrev output/statsbudsjett-2025.jsonl\n",
      "\n",
      "âœ… Ferdig! Output: output/statsbudsjett-2025.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/zfgffxv133jfcvdrwt2l6qcm0000gn/T/ipykernel_30970/922006593.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"retrieved_at\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n"
     ]
    }
   ],
   "source": [
    "# Konfigurasjon\n",
    "PDF_PATH = Path(\"../../data/dokumentavgift-2025.pdf\")\n",
    "OUTPUT_DIR = Path(\"./output\")\n",
    "SOURCE_NAME = \"Statsbudsjett 2025\"\n",
    "DOMAIN = \"offentlig\"\n",
    "\n",
    "# KjÃ¸r konvertering\n",
    "output_file = extract_pdf_to_jsonl(\n",
    "    pdf_path=PDF_PATH,\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    source=SOURCE_NAME,\n",
    "    domain=DOMAIN,\n",
    "    start_page=0,\n",
    "    end_page=None,  # None = alle sider\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Ferdig! Output: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51013e",
   "metadata": {},
   "source": [
    "## Les og inspiser resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befefa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Statsbudsjett 2025\n",
      "Domain: offentlig\n",
      "Text length: 546690 chars\n",
      "\n",
      "First 500 chars:\n",
      "(Korrigert utgave per 14.11.2025)\n",
      "\n",
      "# **Meld. St. 1**\n",
      "\n",
      "###### (2025 â€“ 2026) Melding til Stortinget\n",
      "\n",
      "### Nasjonalbudsjettet 2026\n",
      "\n",
      "# **Meld. St. 1**\n",
      "\n",
      "###### (2025â€“2026) Melding til Stortinget\n",
      "\n",
      "### Nasjonalbudsjettet 2026\n",
      "\n",
      "##### **Innhold**\n",
      "\n",
      "**1** **Hovedlinjer i den Ã¸konomiske**\n",
      "**politikken og utsiktene**\n",
      "**for norsk Ã¸konomi** ...................... 5\n",
      "\n",
      "**2** **De Ã¸konomiske utsiktene** ......... 12\n",
      "2.1 Internasjonal konjunktursituasjon .......................................... 12\n",
      "2.2 Norsk konjun...\n"
     ]
    }
   ],
   "source": [
    "# Les JSONL-fila\n",
    "with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "print(f\"Source: {data['source']}\")\n",
    "print(f\"Domain: {data['domain']}\")\n",
    "print(f\"Text length: {len(data['text'])} chars\")\n",
    "print(f\"\\nFirst 500 chars:\\n{data['text'][:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc2f355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Markdown lagret til: output/statsbudsjett-2025.md\n",
      "ðŸ“Š StÃ¸rrelse: 546,690 tegn\n"
     ]
    }
   ],
   "source": [
    "# Lagre markdown direkte til fil\n",
    "md_output = OUTPUT_DIR / f\"{SOURCE_NAME.lower().replace(' ', '-')}.md\"\n",
    "md_output.write_text(data['text'], encoding='utf-8')\n",
    "print(f\"âœ… Markdown lagret til: {md_output}\")\n",
    "print(f\"ðŸ“Š StÃ¸rrelse: {len(data['text']):,} tegn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf19ed",
   "metadata": {},
   "source": [
    "# Chunking Strategier\n",
    "\n",
    "Vi tester tre forskjellige chunking strategier:\n",
    "1. **Naive**: Split pÃ¥ 200 tegn\n",
    "2. **Overlap**: Behold overlap mellom chunks, ikke split pÃ¥ headings\n",
    "3. **Metadata**: Legg til kontekst fra markdown headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff020bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer chunking bibliotek (kjÃ¸r hvis nÃ¸dvendig)\n",
    "# !pip install langchain-text-splitters pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e80584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a69c4",
   "metadata": {},
   "source": [
    "## Strategi 1: Naive Chunking (200 tegn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714ac948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Naive chunking: 2734 chunks\n",
      "\n",
      "Eksempel chunk #5:\n",
      "{'chunk_id': 5, 'text': 'finanser\\n\\n     - g sammenligning med\\nandre land ....................................... 68\\n\\n**4** **Andre deler av den**\\n**Ã¸konomiske politikken** .............. 78\\n4.1 Pengepolitikken ...............', 'strategy': 'naive', 'char_count': 200}\n"
     ]
    }
   ],
   "source": [
    "def naive_chunking(text: str, chunk_size: int = 200) -> list[dict]:\n",
    "    \"\"\"Split text naivt pÃ¥ chunk_size tegn\"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        chunk_text = text[i:i + chunk_size]\n",
    "        chunks.append({\n",
    "            \"chunk_id\": i // chunk_size,\n",
    "            \"text\": chunk_text,\n",
    "            \"strategy\": \"naive\",\n",
    "            \"char_count\": len(chunk_text)\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "# Test naive chunking\n",
    "naive_chunks = naive_chunking(data['text'], chunk_size=200)\n",
    "print(f\"ðŸ“Š Naive chunking: {len(naive_chunks)} chunks\")\n",
    "print(f\"\\nEksempel chunk #{5}:\")\n",
    "print(naive_chunks[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816062d",
   "metadata": {},
   "source": [
    "## Strategi 2: Overlap Chunking (med overlap, respekter strukturer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3cc1de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Overlap chunking: 1580 chunks\n",
      "\n",
      "Eksempel chunk #5:\n",
      "{'chunk_id': 5, 'text': '5.2 Arbeidskraft .................................... 105\\n\\n5.3 Produktivitet ................................... 118\\n5.4 Effektiv offentlig ressursbruk ....... 133\\n\\n**6** **Velferd, fordeling og ulikhet** .... 141\\n6.1 MÃ¥ling av velferd, livskvalitet\\n\\n       - g levekÃ¥r ....................................... 143\\n6.2 Ã˜konomisk ulikhet i Norge .......... 145\\n\\n**Vedlegg**\\n1 Beregning av strukturell', 'strategy': 'overlap', 'char_count': 398, 'overlap_size': 100}\n",
      "\n",
      "ðŸ”— Overlap mellom chunk 5 og 6:\n",
      "Chunk 5 slutt: ......... 145\n",
      "\n",
      "**Vedlegg**\n",
      "1 Beregning av strukturell\n",
      "Chunk 6 start: **Vedlegg**\n",
      "1 Beregning av strukturell\n",
      "\n",
      "      - lj...\n"
     ]
    }
   ],
   "source": [
    "def overlap_chunking(text: str, chunk_size: int = 500, overlap: int = 100) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Split text med overlap, prÃ¸v Ã¥ ikke splitte midt i setninger\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],  # Prioriter naturlige skilletegn\n",
    "    )\n",
    "    \n",
    "    splits = text_splitter.split_text(text)\n",
    "    chunks = []\n",
    "    for i, chunk_text in enumerate(splits):\n",
    "        chunks.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk_text,\n",
    "            \"strategy\": \"overlap\",\n",
    "            \"char_count\": len(chunk_text),\n",
    "            \"overlap_size\": overlap\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "# Test overlap chunking\n",
    "overlap_chunks = overlap_chunking(data['text'], chunk_size=500, overlap=100)\n",
    "print(f\"ðŸ“Š Overlap chunking: {len(overlap_chunks)} chunks\")\n",
    "print(f\"\\nEksempel chunk #{5}:\")\n",
    "print(overlap_chunks[5])\n",
    "print(f\"\\nðŸ”— Overlap mellom chunk 5 og 6:\")\n",
    "if len(overlap_chunks) > 6:\n",
    "    # Vis overlap\n",
    "    chunk5_end = overlap_chunks[5]['text'][-50:]\n",
    "    chunk6_start = overlap_chunks[6]['text'][:50]\n",
    "    print(f\"Chunk 5 slutt: ...{chunk5_end}\")\n",
    "    print(f\"Chunk 6 start: {chunk6_start}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ec536",
   "metadata": {},
   "source": [
    "## Strategi 3: Metadata Chunking (med markdown headers som kontekst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Metadata chunking: 1260 chunks\n",
      "\n",
      "Eksempel chunk med metadata:\n",
      "\n",
      "Chunk #0:\n",
      "Context: Dette innholdet er fra kapittel 'Innhold' og handler om 'TilrÃ¥ding fra Finansdepartementet 7. oktober 2025,'\n",
      "Metadata: {'h5': '**Innhold**'}\n",
      "Text preview: (Korrigert utgave per 14.11.2025)  \n",
      "# **Meld. St. 1**  \n",
      "###### (2025 â€“ 2026) Melding til Stortinget  \n",
      "### Nasjonalbudsjettet 2026  \n",
      "# **Meld. St. 1**  \n",
      "###### (2025â€“2026) Melding til Stortinget  \n",
      "### ...\n"
     ]
    }
   ],
   "source": [
    "def metadata_chunking(text: str, chunk_size: int = 500, overlap: int = 50) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Split basert pÃ¥ markdown headers og legg til metadata fra heading-hierarkiet.\n",
    "    Format: 'Dette innholdet er i kategori <h1> og handler om <h2>'\n",
    "    \"\"\"\n",
    "    # FÃ¸rst: Split basert pÃ¥ markdown headers\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"h1\"),\n",
    "        (\"##\", \"h2\"),\n",
    "        (\"###\", \"h3\"),\n",
    "    ]\n",
    "    \n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=False  # Behold headers i teksten\n",
    "    )\n",
    "    \n",
    "    md_header_splits = markdown_splitter.split_text(text)\n",
    "    \n",
    "    # Deretter: Split hver seksjon videre med overlap hvis den er for stor\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    for doc in md_header_splits:\n",
    "        # Hent metadata (headers)\n",
    "        metadata = doc.metadata if hasattr(doc, 'metadata') else {}\n",
    "        content = doc.page_content if hasattr(doc, 'page_content') else str(doc)\n",
    "        \n",
    "        # Bygg kontekst-streng fra headers\n",
    "        context_parts = []\n",
    "        if 'h1' in metadata:\n",
    "            context_parts.append(f\"kategori '{metadata['h1']}'\")\n",
    "        if 'h2' in metadata:\n",
    "            context_parts.append(f\"handler om '{metadata['h2']}'\")\n",
    "        if 'h3' in metadata:\n",
    "            context_parts.append(f\"underkategori '{metadata['h3']}'\")\n",
    "        \n",
    "        context_string = \"Dette innholdet er i \" + \" og \".join(context_parts) if context_parts else \"\"\n",
    "        \n",
    "        # Split videre hvis nÃ¸dvendig\n",
    "        if len(content) > chunk_size:\n",
    "            sub_chunks = text_splitter.split_text(content)\n",
    "            for sub_chunk in sub_chunks:\n",
    "                chunks.append({\n",
    "                    \"chunk_id\": chunk_id,\n",
    "                    \"text\": sub_chunk,\n",
    "                    \"context\": context_string,\n",
    "                    \"metadata\": metadata,\n",
    "                    \"strategy\": \"metadata\",\n",
    "                    \"char_count\": len(sub_chunk),\n",
    "                })\n",
    "                chunk_id += 1\n",
    "        else:\n",
    "            chunks.append({\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"text\": content,\n",
    "                \"context\": context_string,\n",
    "                \"metadata\": metadata,\n",
    "                \"strategy\": \"metadata\",\n",
    "                \"char_count\": len(content),\n",
    "            })\n",
    "            chunk_id += 1\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test metadata chunking\n",
    "metadata_chunks = metadata_chunking(data['text'], chunk_size=500, overlap=50)\n",
    "print(f\"ðŸ“Š Metadata chunking: {len(metadata_chunks)} chunks\")\n",
    "print(f\"\\nEksempel chunk med metadata:\")\n",
    "for i, chunk in enumerate(metadata_chunks[:5]):\n",
    "    if chunk['metadata']:  # Vis fÃ¸rste chunk med metadata\n",
    "        print(f\"\\nChunk #{chunk['chunk_id']}:\")\n",
    "        print(f\"Context: {chunk['context']}\")\n",
    "        print(f\"Metadata: {chunk['metadata']}\")\n",
    "        print(f\"Text preview: {chunk['text'][:200]}...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a05e89",
   "metadata": {},
   "source": [
    "## Sammenligning av strategier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b98bda1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Sammenligning av chunking strategier:\n",
      "\n",
      "Strategi  Antall chunks  Gj.snitt stÃ¸rrelse       Overlap     Metadata\n",
      "   Naive           2734          199.959766           Nei          Nei\n",
      " Overlap           1580          375.341139 Ja (100 tegn)          Nei\n",
      "Metadata           1260          454.423810  Ja (50 tegn) Ja (headers)\n"
     ]
    }
   ],
   "source": [
    "# Sammenlign strategiene\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Strategi\": \"Naive\",\n",
    "        \"Antall chunks\": len(naive_chunks),\n",
    "        \"Gj.snitt stÃ¸rrelse\": sum(c['char_count'] for c in naive_chunks) / len(naive_chunks),\n",
    "        \"Overlap\": \"Nei\",\n",
    "        \"Metadata\": \"Nei\"\n",
    "    },\n",
    "    {\n",
    "        \"Strategi\": \"Overlap\",\n",
    "        \"Antall chunks\": len(overlap_chunks),\n",
    "        \"Gj.snitt stÃ¸rrelse\": sum(c['char_count'] for c in overlap_chunks) / len(overlap_chunks),\n",
    "        \"Overlap\": \"Ja (100 tegn)\",\n",
    "        \"Metadata\": \"Nei\"\n",
    "    },\n",
    "    {\n",
    "        \"Strategi\": \"Metadata\",\n",
    "        \"Antall chunks\": len(metadata_chunks),\n",
    "        \"Gj.snitt stÃ¸rrelse\": sum(c['char_count'] for c in metadata_chunks) / len(metadata_chunks),\n",
    "        \"Overlap\": \"Ja (50 tegn)\",\n",
    "        \"Metadata\": \"Ja (headers)\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"ðŸ“Š Sammenligning av chunking strategier:\\n\")\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dcfa72",
   "metadata": {},
   "source": [
    "## Lagre chunks til JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec39af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Lagret 2734 chunks til output/chunks_naive.jsonl\n",
      "âœ… Lagret 1580 chunks til output/chunks_overlap.jsonl\n",
      "âœ… Lagret 1260 chunks til output/chunks_metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Lagre hver strategi til egen fil\n",
    "strategies = {\n",
    "    \"naive\": naive_chunks,\n",
    "    \"overlap\": overlap_chunks,\n",
    "    \"metadata\": metadata_chunks\n",
    "}\n",
    "\n",
    "for strategy_name, chunks in strategies.items():\n",
    "    output_path = OUTPUT_DIR / f\"chunks_{strategy_name}.jsonl\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for chunk in chunks:\n",
    "            f.write(json.dumps(chunk, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"âœ… Lagret {len(chunks)} chunks til {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb51a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
