{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.5-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-6.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-6.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.1-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "  Using cached torch-2.9.1-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Using cached numba-0.62.1.tar.gz (2.7 MB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Using cached numba-0.62.1.tar.gz (2.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25l  Installing build dependencies ... \u001b[?25l-done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m51\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m48\u001b[0m, in \u001b[35m_guard_py_ver\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mRuntimeError\u001b[0m: \u001b[35mCannot install on Python version 3.14.0; only versions >=3.10,<3.14 are supported.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31mERROR: Failed to build 'numba' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0merror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-zg4rgslk/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m51\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m48\u001b[0m, in \u001b[35m_guard_py_ver\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mRuntimeError\u001b[0m: \u001b[35mCannot install on Python version 3.14.0; only versions >=3.10,<3.14 are supported.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31mERROR: Failed to build 'numba' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0mPython version: 3.14.0 (main, Oct  7 2025, 09:34:52) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "‚úÖ Pakker installert!\n",
      "Python version: 3.14.0 (main, Oct  7 2025, 09:34:52) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "‚úÖ Pakker installert!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install numpy pandas sentence-transformers umap-learn plotly scikit-learn\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"‚úÖ Pakker installert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Embedding-modeller for RAG\n",
    "\n",
    "**M√•l:** Forst√• hvordan valg av embedding-modell p√•virker retrieval-kvaliteten i et RAG-system.\n",
    "\n",
    "## Hva er en embedding?\n",
    "\n",
    "En embedding er en **numerisk representasjon** av tekst som fanger opp semantisk mening. \n",
    "Tekst som betyr lignende ting vil ha vektorer som ligger n√¶r hverandre i vektorrommet.\n",
    "\n",
    "```\n",
    "\"Hva er dokumentavgift?\" ‚Üí [0.12, -0.34, 0.56, ..., 0.78]  (768 dimensjoner)\n",
    "\"Dokumentavgift forklart\" ‚Üí [0.11, -0.32, 0.55, ..., 0.79]  (lignende vektor!)\n",
    "\"Oppskrift p√• pizza\"     ‚Üí [0.89, 0.23, -0.45, ..., -0.12] (helt annen vektor)\n",
    "```\n",
    "\n",
    "## Hvorfor er valg av modell viktig?\n",
    "\n",
    "| Aspekt | P√•virkning |\n",
    "|--------|------------|\n",
    "| **Dimensjonalitet** | H√∏yere = mer presis, men tregere og mer lagring |\n",
    "| **Spr√•kst√∏tte** | Kritisk for norske dokumenter! |\n",
    "| **Treningsdata** | Modeller trent p√• juridisk tekst forst√•r juss bedre |\n",
    "| **Modellst√∏rrelse** | St√∏rre modeller er ofte bedre, men tregere |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installer pakker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-6.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-6.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.5-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.5-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.1-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.1-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Using cached numba-0.62.1.tar.gz (2.7 MB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Using cached numba-0.62.1.tar.gz (2.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25l  Installing build dependencies ... \u001b[?25l-done\n",
      "\bdone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m51\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m48\u001b[0m, in \u001b[35m_guard_py_ver\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mRuntimeError\u001b[0m: \u001b[35mCannot install on Python version 3.14.0; only versions >=3.10,<3.14 are supported.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31mERROR: Failed to build 'numba' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0merror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Users/simen/prosjekter/faggruppe/dsm-2025-rag/venv/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/sh/t1kb_fwn67l_f8zrzb26bct40000gn/T/pip-build-env-mpq81wqp/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m51\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m48\u001b[0m, in \u001b[35m_guard_py_ver\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mRuntimeError\u001b[0m: \u001b[35mCannot install on Python version 3.14.0; only versions >=3.10,<3.14 are supported.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31mERROR: Failed to build 'numba' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Kj√∏r dette f√∏rst for √• installere n√∏dvendige pakker\n",
    "# UMAP krever Python <3.14, s√• vi bruker PCA som alternativ\n",
    "!pip install sentence-transformers plotly pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Last inn chunks fra chunking-steget\n",
    "\n",
    "Vi bruker chunks som allerede er laget av chunking-notebooken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last inn metadata chunks (beste kvalitet fra chunking-steget)\n",
    "chunks_path = Path(\"../output/chunks_metadata.jsonl\")\n",
    "\n",
    "chunks = []\n",
    "with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))\n",
    "\n",
    "print(f\"üìä Lastet {len(chunks)} chunks\")\n",
    "print(f\"\\nüìù Eksempel chunk:\")\n",
    "print(f\"   Text: {chunks[20]['text'][:100]}...\")\n",
    "print(f\"   Context: {chunks[20].get('context', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Definer embedding-modeller\n",
    "\n",
    "Vi sammenligner **tre forskjellige open source modeller** med ulike egenskaper:\n",
    "\n",
    "| Modell | Dimensjoner | Spr√•k | St√∏rrelse | Bruksomr√•de |\n",
    "|--------|-------------|-------|-----------|-------------|\n",
    "| `all-MiniLM-L6-v2` | 384 | Engelsk | 80 MB | Rask, generell |\n",
    "| `paraphrase-multilingual-MiniLM-L12-v2` | 384 | 50+ spr√•k | 420 MB | Flerspr√•klig |\n",
    "| `multilingual-e5-large` | 1024 | 100 spr√•k | 2.2 GB | State-of-the-art |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definer modellene vi skal teste\n",
    "MODELS = {\n",
    "    \"MiniLM-EN\": {\n",
    "        \"name\": \"all-MiniLM-L6-v2\",\n",
    "        \"dim\": 384,\n",
    "        \"desc\": \"Rask engelsk modell\",\n",
    "        \"color\": \"#FF6B6B\"\n",
    "    },\n",
    "    \"MiniLM-Multi\": {\n",
    "        \"name\": \"paraphrase-multilingual-MiniLM-L12-v2\", \n",
    "        \"dim\": 384,\n",
    "        \"desc\": \"Flerspr√•klig (50+ spr√•k)\",\n",
    "        \"color\": \"#4ECDC4\"\n",
    "    },\n",
    "    \"E5-Large\": {\n",
    "        \"name\": \"intfloat/multilingual-e5-large\",\n",
    "        \"dim\": 1024,\n",
    "        \"desc\": \"State-of-the-art multilingual\",\n",
    "        \"color\": \"#45B7D1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ü§ñ Modeller som skal testes:\")\n",
    "for key, info in MODELS.items():\n",
    "    print(f\"   ‚Ä¢ {key}: {info['desc']} ({info['dim']} dim)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last inn modellene (kan ta litt tid f√∏rste gang)\n",
    "models = {}\n",
    "\n",
    "for key, info in MODELS.items():\n",
    "    print(f\"‚è≥ Laster {key}...\")\n",
    "    start = time.time()\n",
    "    models[key] = SentenceTransformer(info[\"name\"])\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"   ‚úÖ Lastet p√• {elapsed:.1f}s\")\n",
    "\n",
    "print(\"\\nüéâ Alle modeller lastet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Generer embeddings\n",
    "\n",
    "Vi genererer embeddings for alle chunks med hver modell og m√•ler tiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hent ut tekst fra chunks\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "\n",
    "# For E5-modellen m√• vi legge til \"passage: \" prefix\n",
    "texts_e5 = [f\"passage: {t}\" for t in texts]\n",
    "\n",
    "# Generer embeddings med hver modell\n",
    "embeddings = {}\n",
    "timing = {}\n",
    "\n",
    "for key, model in models.items():\n",
    "    print(f\"\\n‚è≥ Genererer embeddings med {key}...\")\n",
    "    \n",
    "    # E5 krever \"passage:\" prefix for dokumenter\n",
    "    input_texts = texts_e5 if \"E5\" in key else texts\n",
    "    \n",
    "    start = time.time()\n",
    "    emb = model.encode(input_texts, show_progress_bar=True, normalize_embeddings=True)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    embeddings[key] = emb\n",
    "    timing[key] = elapsed\n",
    "    \n",
    "    print(f\"   ‚úÖ {len(texts)} chunks p√• {elapsed:.1f}s ({len(texts)/elapsed:.1f} chunks/sek)\")\n",
    "    print(f\"   üìê Shape: {emb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Sammenlign ytelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag sammenligning\n",
    "comparison_data = []\n",
    "for key, info in MODELS.items():\n",
    "    emb = embeddings[key]\n",
    "    comparison_data.append({\n",
    "        \"Modell\": key,\n",
    "        \"Dimensjoner\": info[\"dim\"],\n",
    "        \"Tid (sek)\": f\"{timing[key]:.1f}\",\n",
    "        \"Chunks/sek\": f\"{len(texts)/timing[key]:.1f}\",\n",
    "        \"Minne (MB)\": f\"{emb.nbytes / 1024 / 1024:.1f}\",\n",
    "        \"Beskrivelse\": info[\"desc\"]\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"üìä Ytelsessammenligning:\\n\")\n",
    "print(df_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser ytelse\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\"Tid per modell\", \"Dimensjoner vs Hastighet\"),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "colors = [MODELS[k][\"color\"] for k in MODELS.keys()]\n",
    "\n",
    "# Bar chart: Tid\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(MODELS.keys()),\n",
    "        y=[timing[k] for k in MODELS.keys()],\n",
    "        marker_color=colors,\n",
    "        text=[f\"{timing[k]:.1f}s\" for k in MODELS.keys()],\n",
    "        textposition=\"outside\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Scatter: Dimensjoner vs Hastighet\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[MODELS[k][\"dim\"] for k in MODELS.keys()],\n",
    "        y=[len(texts)/timing[k] for k in MODELS.keys()],\n",
    "        mode=\"markers+text\",\n",
    "        marker=dict(size=20, color=colors),\n",
    "        text=list(MODELS.keys()),\n",
    "        textposition=\"top center\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"‚ö° Ytelsessammenligning av Embedding-modeller\",\n",
    "    showlegend=False,\n",
    "    height=400\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Modell\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Tid (sekunder)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Dimensjoner\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Chunks per sekund\", row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Visualiser embedding-rom med PCA\n",
    "\n",
    "PCA (Principal Component Analysis) lar oss visualisere h√∏y-dimensjonale embeddings i 2D.\n",
    "\n",
    "**Hva ser vi etter?**\n",
    "- Chunks om samme tema skal klynge seg sammen\n",
    "- Forskjellige modeller kan gruppere tekst ulikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduser dimensjoner med PCA for hver modell\n",
    "pca_results = {}\n",
    "\n",
    "for key in MODELS.keys():\n",
    "    print(f\"‚è≥ PCA for {key}...\")\n",
    "    reducer = PCA(n_components=2, random_state=42)\n",
    "    pca_results[key] = reducer.fit_transform(embeddings[key])\n",
    "    print(f\"   ‚úÖ Ferdig (forklart varians: {sum(reducer.explained_variance_ratio_):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hent metadata for fargelegging\n",
    "# Bruk h1 header som kategori\n",
    "categories = []\n",
    "for c in chunks:\n",
    "    meta = c.get(\"metadata\", {})\n",
    "    cat = meta.get(\"h3\", meta.get(\"h2\", meta.get(\"h1\", \"Ukjent\")))\n",
    "    # Forenkle kategorinavnet\n",
    "    cat = cat.replace(\"**\", \"\").strip()[:30]\n",
    "    categories.append(cat)\n",
    "\n",
    "# Finn de 8 vanligste kategoriene\n",
    "from collections import Counter\n",
    "cat_counts = Counter(categories)\n",
    "top_cats = [c[0] for c in cat_counts.most_common(8)]\n",
    "categories_simplified = [c if c in top_cats else \"Andre\" for c in categories]\n",
    "\n",
    "print(f\"üìÇ Kategorier funnet: {len(set(categories_simplified))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag PCA visualisering for alle modeller\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=[f\"{k} ({MODELS[k]['dim']}d)\" for k in MODELS.keys()]\n",
    ")\n",
    "\n",
    "for i, key in enumerate(MODELS.keys(), 1):\n",
    "    pca_2d = pca_results[key]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pca_2d[:, 0],\n",
    "            y=pca_2d[:, 1],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                opacity=0.7,\n",
    "                color=[hash(c) % 10 for c in categories_simplified],\n",
    "                colorscale=\"Viridis\"\n",
    "            ),\n",
    "            text=[f\"{c}\\n{chunks[j]['text'][:50]}...\" for j, c in enumerate(categories_simplified)],\n",
    "            hovertemplate=\"%{text}<extra></extra>\"\n",
    "        ),\n",
    "        row=1, col=i\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üé® PCA: Hvordan ser modellene p√• dokumentet?\",\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Test retrieval: Hvilken modell finner best svar?\n",
    "\n",
    "Vi tester modellene med noen norske sp√∏rsm√•l om dokumentavgift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-sp√∏rsm√•l p√• norsk\n",
    "test_queries = [\n",
    "    \"Hva er dokumentavgift?\",\n",
    "    \"Hvor mye er dokumentavgiften i prosent?\",\n",
    "    \"N√•r slipper man √• betale dokumentavgift?\",\n",
    "    \"Hva skjer ved arv av eiendom?\",\n",
    "    \"Hvordan beregnes avgiftsgrunnlaget?\"\n",
    "]\n",
    "\n",
    "def search(query: str, model_key: str, top_k: int = 3) -> list:\n",
    "    \"\"\"S√∏k etter mest relevante chunks for en query\"\"\"\n",
    "    model = models[model_key]\n",
    "    \n",
    "    # E5 krever \"query:\" prefix\n",
    "    if \"E5\" in model_key:\n",
    "        query = f\"query: {query}\"\n",
    "    \n",
    "    query_emb = model.encode([query], normalize_embeddings=True)\n",
    "    \n",
    "    # Beregn similarity\n",
    "    similarities = cosine_similarity(query_emb, embeddings[model_key])[0]\n",
    "    \n",
    "    # Hent top-k\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"chunk_id\": chunks[idx][\"chunk_id\"],\n",
    "            \"score\": float(similarities[idx]),\n",
    "            \"text\": chunks[idx][\"text\"][:200],\n",
    "            \"context\": chunks[idx].get(\"context\", \"\")\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test alle modeller med f√∏rste query\n",
    "query = test_queries[0]\n",
    "print(f\"üîç Query: '{query}'\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model_key in MODELS.keys():\n",
    "    print(f\"\\nüìå {model_key} ({MODELS[model_key]['desc']})\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    results = search(query, model_key, top_k=3)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"  {i}. [Score: {r['score']:.3f}] {r['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sammenlign alle queries visuelt\n",
    "all_results = []\n",
    "\n",
    "for query in test_queries:\n",
    "    for model_key in MODELS.keys():\n",
    "        results = search(query, model_key, top_k=1)\n",
    "        all_results.append({\n",
    "            \"Query\": query[:40] + \"...\",\n",
    "            \"Modell\": model_key,\n",
    "            \"Top Score\": results[0][\"score\"],\n",
    "            \"Chunk ID\": results[0][\"chunk_id\"]\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Pivot for heatmap\n",
    "pivot = df_results.pivot(index=\"Query\", columns=\"Modell\", values=\"Top Score\")\n",
    "\n",
    "fig = px.imshow(\n",
    "    pivot,\n",
    "    labels=dict(x=\"Modell\", y=\"Sp√∏rsm√•l\", color=\"Similarity Score\"),\n",
    "    color_continuous_scale=\"RdYlGn\",\n",
    "    aspect=\"auto\",\n",
    "    text_auto=\".2f\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üéØ Retrieval Scores per Modell og Sp√∏rsm√•l\",\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üá≥üá¥ Spr√•ktest: Hvordan h√•ndterer modellene norsk?\n",
    "\n",
    "Vi tester hvordan modellene matcher norske vs engelske queries mot norsk tekst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norsk vs Engelsk query\n",
    "language_pairs = [\n",
    "    (\"Hva er dokumentavgift?\", \"What is document tax?\"),\n",
    "    (\"Fritak ved arv\", \"Exemption for inheritance\"),\n",
    "    (\"Beregning av avgift\", \"Calculation of tax\")\n",
    "]\n",
    "\n",
    "print(\"üá≥üá¥ Norsk vs üá¨üáß Engelsk queries p√• norsk dokument\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for no_query, en_query in language_pairs:\n",
    "    print(f\"\\nüìù NO: '{no_query}' | EN: '{en_query}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for model_key in MODELS.keys():\n",
    "        no_results = search(no_query, model_key, top_k=1)\n",
    "        en_results = search(en_query, model_key, top_k=1)\n",
    "        \n",
    "        no_score = no_results[0][\"score\"]\n",
    "        en_score = en_results[0][\"score\"]\n",
    "        diff = no_score - en_score\n",
    "        \n",
    "        emoji = \"‚úÖ\" if diff > 0 else \"‚ö†Ô∏è\"\n",
    "        print(f\"  {model_key:15} | NO: {no_score:.3f} | EN: {en_score:.3f} | Diff: {diff:+.3f} {emoji}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Intra-cluster similarity: Hvor konsistente er embeddings?\n",
    "\n",
    "Vi m√•ler hvor like chunks innenfor samme kategori er - h√∏yere = bedre semantisk forst√•else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Grupper chunks per kategori\n",
    "cat_to_indices = defaultdict(list)\n",
    "for i, cat in enumerate(categories_simplified):\n",
    "    if cat != \"Andre\":  # Skip \"Andre\"\n",
    "        cat_to_indices[cat].append(i)\n",
    "\n",
    "# Beregn gjennomsnittlig intra-cluster similarity\n",
    "cluster_scores = []\n",
    "\n",
    "for model_key in MODELS.keys():\n",
    "    emb = embeddings[model_key]\n",
    "    \n",
    "    similarities = []\n",
    "    for cat, indices in cat_to_indices.items():\n",
    "        if len(indices) >= 2:\n",
    "            cat_emb = emb[indices]\n",
    "            sim_matrix = cosine_similarity(cat_emb)\n",
    "            # Hent √∏vre triangel (unng√• diagonalen)\n",
    "            upper_tri = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "            similarities.extend(upper_tri)\n",
    "    \n",
    "    avg_sim = np.mean(similarities)\n",
    "    cluster_scores.append({\n",
    "        \"Modell\": model_key,\n",
    "        \"Avg Intra-Cluster Similarity\": avg_sim\n",
    "    })\n",
    "\n",
    "df_cluster = pd.DataFrame(cluster_scores)\n",
    "\n",
    "fig = px.bar(\n",
    "    df_cluster,\n",
    "    x=\"Modell\",\n",
    "    y=\"Avg Intra-Cluster Similarity\",\n",
    "    color=\"Modell\",\n",
    "    color_discrete_sequence=[MODELS[k][\"color\"] for k in MODELS.keys()],\n",
    "    text_auto=\".3f\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üìä Intra-Cluster Similarity (h√∏yere = bedre gruppering)\",\n",
    "    showlegend=False,\n",
    "    yaxis_range=[0, 1]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Lagre embeddings for senere bruk\n",
    "\n",
    "Vi lagrer embeddings slik at de kan brukes i retrieval-steget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"./output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for model_key in MODELS.keys():\n",
    "    # Lagre som numpy\n",
    "    np.save(output_dir / f\"embeddings_{model_key}.npy\", embeddings[model_key])\n",
    "    print(f\"‚úÖ Lagret embeddings_{model_key}.npy ({embeddings[model_key].shape})\")\n",
    "\n",
    "print(f\"\\nüìÇ Filer lagret i {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Oppsummering\n",
    "\n",
    "### Hva l√¶rte vi?\n",
    "\n",
    "1. **Spr√•kst√∏tte er kritisk** - Engelske modeller sliter med norsk tekst\n",
    "2. **Dimensjonalitet ‚â† Kvalitet** - Flere dimensjoner betyr ikke alltid bedre resultater\n",
    "3. **Trade-offs finnes** - Raskere modeller kan v√¶re \"good enough\" for mange use cases\n",
    "4. **Test p√• dine data** - Benchmark-resultater gjelder ikke alltid for din use case\n",
    "\n",
    "### Anbefalinger for norske RAG-systemer\n",
    "\n",
    "| Scenario | Anbefalt modell |\n",
    "|----------|----------------|\n",
    "| Produksjon med norsk tekst | `multilingual-e5-large` |\n",
    "| Rask prototyping | `paraphrase-multilingual-MiniLM-L12-v2` |\n",
    "| Kun engelsk tekst | `all-MiniLM-L6-v2` |\n",
    "\n",
    "### Neste steg\n",
    "\n",
    "- **Hybrids√∏k** - Kombiner med BM25 for bedre resultater\n",
    "- **Re-ranking** - Bruk cross-encoder for √• forbedre ranking\n",
    "- **Evaluering** - M√•l MRR, Recall@k p√• reelle test-sett"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
